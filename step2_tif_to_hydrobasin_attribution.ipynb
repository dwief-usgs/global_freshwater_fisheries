{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Attribute Tiff Data to HydroBasins Level 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributing information from Tiff files to HydroBASINS Level 12.  Methods are primarly from the attribution and file_management modules in utils and use Rasterio, Rasterstat, Geopandas packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "\n",
    "#### Required Python Package(s): \n",
    "    * rasterstats\n",
    "    * rasterio\n",
    "    * pandas\n",
    "    * json\n",
    "    \n",
    "#### Optional Python Package(s) :\n",
    "    * timeit (this allows user to test processing time and calibrate runs accordingly)\n",
    "    \n",
    "#### Required File(s):\n",
    "    * 'data/var/tif_var_file_info.json' from step 1c, note if this file is in a different directory user must specify appropriate directory.  This example assumes the file is in 'data/var' and that the notebook remains as downloaded.\n",
    "    * HydroBASINS level 12 data.  In this example we use the pickled geodataframe ('data/basins_lvl12_gdf.pkl') and list of IDs 'data/basins_lvl12.txt' from step 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import json\n",
    "from rasterstats import zonal_stats\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from utils import file_management as f_mng\n",
    "from utils import attribution as attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will import tif file processing information and HydroBASIN data that we stored in step 1C (see step1_data_management.ipynb).  \n",
    "\n",
    "We then determine bounds for each HydroBASIN.  In some cases TIF files do not have global coverage.  Instead of running the entire (CPU intense) zonal statistics process on each TIF we run a quick box intersection algorithm to test which TIF files likely have relevant data for each basin and only run the rest of the attribution process on these files. \n",
    "\n",
    "Note there is a lot of data being loaded, the next cell may take over a minute to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import file processing information\n",
    "with open(\"data/var/tif_vars_file_info.json\", \"r\") as all_file_info:\n",
    "    json_file_info = json.load(all_file_info)\n",
    "    \n",
    "#Read in list of HYBAS_IDs (see step1_data_management.ipynb).  Provides list of IDs to process.\n",
    "hybas_id_list=f_mng.read_pkl_df('data/basins_lvl12.txt')\n",
    "\n",
    "#Read in pickled level 12 HydroBASINS (see step1_data_management.ipynb)\n",
    "gdf = f_mng.read_pkl_gdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is only running on a few basins as an example. To run on all basins remove [0:3] selection from hybas_id_list[0:3].  When running all basins this can take hours or days using one processor.  See the example of using multiprocessing in Python to run attribution of multiple tif files for all basins (XXXXXX.py).  Note a few additional packages are required.  In addition multiprocessing may require additional configurations for Windows users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "all_stats = []\n",
    "\n",
    "#run attribution on each basin, one basin at a time for a subset of basins indexed 0 to 3\n",
    "for basin in hybas_id_list[0:3]:\n",
    "    \n",
    "    #Select row from geodataframe with basin information, including bounding box info\n",
    "    basin_info_gdf = gdf.loc[gdf['HYBAS_ID']==int(basin)]\n",
    "    pfaf_12 = basin_info_gdf.iloc[0]['PFAF_ID']\n",
    "    sub_area = float((basin_info_gdf.iloc[0])['SUB_AREA'])\n",
    "    \n",
    "    bbox_gdf = basin_info_gdf.bounds\n",
    "\n",
    "    #Initiate basin stat object, this will help manage stats as created for the basin\n",
    "    basin_info = attr.Stats(basin, pfaf_12, sub_area)\n",
    "\n",
    "    #Add bounding box of basin to object\n",
    "    basin_info.bounds((bbox_gdf['minx']),(bbox_gdf['maxx']),(bbox_gdf['miny']), (bbox_gdf['maxy']))\n",
    "    #basin_info.bounds((basin_info_gdf['minx']),(basin_info_gdf['maxx']),(basin_info_gdf['miny']), (basin_info_gdf['maxy']))\n",
    "    \n",
    "    # loop through each record (representing a file in the folder containing variable data) in json_file_info \n",
    "    for file in json_file_info:\n",
    "            \n",
    "        var_bounds = file['bounds']\n",
    "\n",
    "        #evaluate if data in file spatialy overlaps spatial object using bounds, process if overlap/intersection occurs\n",
    "        basin_info.evaluate_intersection(var_bounds)\n",
    "        #If needed run zonal stats\n",
    "        basin_info.run_zonal_stats(basin_info_gdf, file)\n",
    "    \n",
    "    #Add stats to a common list\n",
    "    all_stats = basin_info.add_to_all_stats(all_stats)\n",
    "    basin_info = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First record in all_stats.  Note that we are capturing more data than we likely need for our end product.  These information can help us test results and help others track where data are coming from.\n",
    "\n",
    "Each Record contains the following:\n",
    " * id: hybas_id from hydrobasins (level 12)\n",
    " * pfaf_12: pfaf value from HydroBASINS\n",
    " * suite of summaries: \n",
    "         * label_stat0:value0, label_stat1:value1... label_statx:valuex\n",
    "         * src_file: tif files used in summary and how they evaluated in the bounds_eval method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc2015_bare_cov': {'lc2015_bare_cov_mean': 0.0,\n",
       "  'lc2015_bare_cov_count': 12881,\n",
       "  'lc2015_bare_cov_nodata': 0.0,\n",
       "  'src_file': [{'file_name': 'E020N20_ProbaV_LC100_epoch2015_global_v2.0.1_bare-coverfraction-layer_EPSG-4326.tif',\n",
       "    'bounds_eval': 1}]},\n",
       " 'lc2015_grass_cov': {'lc2015_grass_cov_mean': 39.11241363248195,\n",
       "  'lc2015_grass_cov_count': 12881,\n",
       "  'lc2015_grass_cov_nodata': 0.0,\n",
       "  'src_file': [{'file_name': 'E020N20_ProbaV_LC100_epoch2015_global_v2.0.1_grass-coverfraction-layer_EPSG-4326.tif',\n",
       "    'bounds_eval': 1}]},\n",
       " 'lc2015_shrub_cov': {'lc2015_shrub_cov_mean': 32.858240819812124,\n",
       "  'lc2015_shrub_cov_count': 12881,\n",
       "  'lc2015_shrub_cov_nodata': 0.0,\n",
       "  'src_file': [{'file_name': 'E020N20_ProbaV_LC100_epoch2015_global_v2.0.1_shrub-coverfraction-layer_EPSG-4326.tif',\n",
       "    'bounds_eval': 1}]},\n",
       " 'lc2015_tree_cov': {'lc2015_tree_cov_mean': 28.023445384675103,\n",
       "  'lc2015_tree_cov_count': 12881,\n",
       "  'lc2015_tree_cov_nodata': 0.0,\n",
       "  'src_file': [{'file_name': 'E020N20_ProbaV_LC100_epoch2015_global_v2.0.1_tree-coverfraction-layer_EPSG-4326.tif',\n",
       "    'bounds_eval': 1}]},\n",
       " 'lc2015_waterseas_cov': {'lc2015_waterseas_cov_mean': 0.0,\n",
       "  'lc2015_waterseas_cov_count': 12881,\n",
       "  'lc2015_waterseas_cov_nodata': 0.0,\n",
       "  'src_file': [{'file_name': 'E020N20_ProbaV_LC100_epoch2015_global_v2.0.1_water-seasonal-coverfraction-layer_EPSG-4326.tif',\n",
       "    'bounds_eval': 1}]},\n",
       " 'lc2015_urban_cov': {'lc2015_urban_cov_mean': 0.0,\n",
       "  'lc2015_urban_cov_count': 12881,\n",
       "  'lc2015_urban_cov_nodata': 0.0,\n",
       "  'src_file': [{'file_name': 'E020N20_ProbaV_LC100_epoch2015_global_v2.0.1_urban-coverfraction-layer_EPSG-4326.tif',\n",
       "    'bounds_eval': 1}]},\n",
       " 'lc2015_waterperm_cov': {'lc2015_waterperm_cov_mean': 0.0,\n",
       "  'lc2015_waterperm_cov_count': 12881,\n",
       "  'lc2015_waterperm_cov_nodata': 0.0,\n",
       "  'src_file': [{'file_name': 'E020N20_ProbaV_LC100_epoch2015_global_v2.0.1_water-permanent-coverfraction-layer_EPSG-4326.tif',\n",
       "    'bounds_eval': 1}]},\n",
       " 'lc2015_moss_cov': {'lc2015_moss_cov_mean': 0.0,\n",
       "  'lc2015_moss_cov_count': 12881,\n",
       "  'lc2015_moss_cov_nodata': 0.0,\n",
       "  'src_file': [{'file_name': 'E020N20_ProbaV_LC100_epoch2015_global_v2.0.1_moss-coverfraction-layer_EPSG-4326.tif',\n",
       "    'bounds_eval': 1}]},\n",
       " 'lc2015_snow_cov': {'lc2015_snow_cov_mean': 0.0,\n",
       "  'lc2015_snow_cov_count': 12881,\n",
       "  'lc2015_snow_cov_nodata': 0.0,\n",
       "  'src_file': [{'file_name': 'E020N20_ProbaV_LC100_epoch2015_global_v2.0.1_snow-coverfraction-layer_EPSG-4326.tif',\n",
       "    'bounds_eval': 1}]},\n",
       " 'lc2015_crops_cov': {'lc2015_crops_cov_mean': 0.005900163030820588,\n",
       "  'lc2015_crops_cov_count': 12881,\n",
       "  'lc2015_crops_cov_nodata': 0.0,\n",
       "  'src_file': [{'file_name': 'E020N20_ProbaV_LC100_epoch2015_global_v2.0.1_crops-coverfraction-layer_EPSG-4326.tif',\n",
       "    'bounds_eval': 1}]},\n",
       " 'id': 1121976320,\n",
       " 'pfaf_12': 172882676400,\n",
       " 'sub_area': 154.8}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show stats for basin id 1121976320\n",
    "all_stats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export information to json file\n",
    "\n",
    "#with open('ouput/tif_att_stats.json', 'w') as outfile:\n",
    "#    json.dump(all_stats, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export information to csv file\n",
    "outfile_name = 'output/tif_att_stats.csv'\n",
    "attr.json_stats_to_csv(all_stats, outfile_name, pfaf_field_nm = 'pfaf_12')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
